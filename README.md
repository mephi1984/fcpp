# Дипломный проект «Поисковая система»

## Описание
Необходимо написать поисковую систему, аналог Google, Яндекс или Yahoo.

Поисковая система будет получать данные с сайтов, строить поисковые индексы и по запросу выдавать релевантные результаты поисковой выдачи.

Поисковая система будет состоять из следующих частей:
1. Программа-"паук", HTTP-клиент задача которого - парсить сайты.
2. Программа-индексатор, задача которого - построить индекс исходя из частоты слов в документах.
3. Программа-поисковик. HTTP-сервер, задача которого - принимать запросы и возвращать результаты поиска.

Для хранения информации следует использовать базу данных PostgreSQL.

Настройки программ следует хранить в ini-файлах.

## Программы
### 1. Программа "паук"

Программа "паук" (spider) или "краулер" (crowler) - это неотъемлемая часть поисковой системы. Эта программа, которая обходит Интернет следуя по ссылкам на веб-страницах. Начиная с одной страницы, эта программа переходит на другие страницы по ссылкам, найденным на этих страницах. "Паук" загружает содержимое каждой страницы в файл для последующего анализа и индексации.

Изнутри программа-"паук" представляет из себя HTTP-клиент, который переходит по ссылкам и скачивает HTML-страницы в файлы на жестком диске. 

Также "паук" взаимодействует с базой данных - он сохраняет в отдельную таблицу DOCUMENTS ссылку на веб-страницу, имя сохраненного файла на жестком диске, а также дату и время сохранения веб-страницы.

В ini-файле конфигурации задается страница, которую необходимо сохранить, и "Паук" начинает свою работу именно с этой страницы. 

В HTML-страницах также существуют ссылки, обозначаемые HTML-тегом `<a href="...">`. "Паук" должен переходить по этим ссылкам и скачивать эти страницы тоже. Для этого "Паук" реализует многопоточную очередь и пул потоков. Очередь состоит из ссылок на скачивание, а пул потоков выполняет задачу по скачиванию веб-страниц с этих ссылок. После скачивания очередной страницы "Паук" собирает все ссылки и добавляет их в очередь на скачивание.

Для сборка ссылок вы можете использовать регулярные выражения, или вы можете подключить библиотеку для XML-парсинга.

"Паук" переходит по страницам не бесконечно. Глубина рекурсии должна быть задана настройкой в ini-файле конфигурации в виде числа. К примеру, если глубина рекурсии задана как 1, то "Паук" анализирует только непосредственно стартовую страницу. Если глубина рекурсии равна 2, то "Паук" анализирует стартовую страницу и страницы, на которые она ссылается. Если глубина рекурсии равна 3, то "Паук", анализирует стартовую страницу, страницы, на которые ссылается стартовая страница, и страницы которые находятся на страницах, на которые стартовая страница, и так далее.

Для реализации HTTP-клиента рекомендуется подключить и использовать библиотеку Boost Beast ( https://www.boost.org/doc/libs/1_82_0/libs/beast/doc/html/index.html ). 

### 2. Программа-индексатор.

Индексатор производит анализ сохраненных веб-страниц для определения ключевых слов и других полезных данных. Индексатор удаляет HTML-теги из страницы, оставляя только чистый текст. Затем индексатор анализирует текст на странице и сохраняет информацию в базе данных, для того чтобы вести поиск по этим данным.

Индексатор выполняет следующие действия последовательно:
1. Для начала, интексатор извлекает из базы данных из таблицы DOCUMENTS список страниц, которые были сохранены после определенной даты и времени. Указанные дата и время должны быть заданы в ini-файле конфигурации.
2. Каждая из извлеченных страниц очищается от HTML тегов. Остается только чистый текст.
3. Из текста извлекаются слова. Слова должны извлекаться без знаков препинания, табуляции, и т.д. Слова должны переводиться в нижний регистр. Для простоты можно отбрасывать все слова короче 3 символов или длиннее 32 символов. 
4. Извлеченные слова сохраняются в базу данных в отдельную таблицу WORDS - если в документе попалось какое-то новое слово, которого еще нет в таблице, то это слово добавляется туда.
3. Анализируется частотность слов в тексте. Индексатор считает, сколько раз слово встречается каждое слово в тексте. Эта информация добавляется в отдельную таблицу DOCUMENTS_WORDS, где каждая запись имеет следующие поля:
 - Первичный ключ
 - Внешний ключ на таблицу DOCUMENTS - документ, который проанализирован
 - Внешний ключ на таблицу WORDS - слово, для которого вычислена частотность
 - Количество упоминаний слова в тексте
 - Дата и время анализа документа

После анализа всех страниц индексатор завершает свою работу.

Вы можете написать индексатор как отдельную программу или вы можете включить ее в состав программы "Паук".

### 3. Программа-поисковик

Программа-поисковик выполняет поиск по базе данных, ранжирует результат и возвращает его пользователю. В настоящих поисковых системах ранжирование выполняется по множеству критериев, однако для простоты будем ранжировать страницу по частоте упоминания искомых слов в документе.

Изнутри поисковик представляет из себя HTTP-сервер, который принимает два вида запросов: POST и GET.

По запросу GET открывается простая статическая HTML-страница с формой поиска. На форме должно быть поле ввода, а также кнопка поиска.

По запросу POST происходит извлечение из базы данных результата запроса и его ранжирование, а затем перед пользователем открывается простая статическая веб-страница с результатами поиска.

Для простоты, запрос можно анализировать только в виде слов, разделенных пробелами. Все прочие знаки препинания игнорируется. Можно также ограничить длину запроса - не более 4х слов. 

Для извлечения данных напишите SQL-запрос. Запрос должен быть следующим: взять документы, в которых встречаются все слова из запроса и отсортировать документы по суммарному количеству упоминаний слов в документа.

Приведу пример для запроса "привет мир". Предположим, если если в документе A слово "привет" встречается 10 раз, а слово "мир" встречается 4 раза, то этот документ имеет релевантность 10 + 4 = 14. Если в документе B слово "привет" встречается 3 раза, а слово "мир" 8 раза, то релевантность его равна 3 + 8 = 11, и он будет находится ниже в выдаче.

Для простоты можете ограничить выдачу, выдавая не более чем 10 результатов поиска.

Полсе выполнения запроса программа должна вернуть статическую HTML-страницу с результатами поиска.

Для реализации HTTP-сервера рекомендуется подключить и использовать библиотеку Boost Beast ( https://www.boost.org/doc/libs/1_82_0/libs/beast/doc/html/index.html ). 


## Полезные материалы
* [Пример HTTP-клиента на Boost Beast](https://www.boost.org/doc/libs/1_82_0/libs/beast/doc/html/beast/quick_start/http_client.html)
* [Пример HTTP-сервера на Boost Beast](https://www.boost.org/doc/libs/1_82_0/libs/beast/examplez/http/server/small/http_server_small.cpp) 

